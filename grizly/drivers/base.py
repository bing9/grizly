import csv
import decimal
import gc
import logging
import os
from abc import ABC, abstractmethod
from copy import deepcopy
from functools import partial
from typing import Any, Callable, Dict, Iterator, List, Optional, Tuple, Union, Literal

import deprecation
import pyarrow as pa
import pyarrow.parquet as pq
import s3fs
from pandas import DataFrame

from ..store import Store
from ..tools.crosstab import Crosstab
from ..utils.functions import copy_df_to_excel, dict_diff
from ..utils.deprecation import deprecated_params
from ..utils.type_mappers import python_to_sql, rds_to_pyarrow, sql_to_python

deprecation.deprecated = partial(deprecation.deprecated, deprecated_in="0.4", removed_in="0.5")
deprecated_params = partial(deprecated_params, deprecated_in="0.4", removed_in="0.4.5")


class BaseDriver(ABC):
    _allowed_agg = ["SUM", "COUNT", "MAX", "MIN", "AVG", "STDDEV", ""]
    _allowed_group_by = _allowed_agg + ["GROUP"]
    _allowed_order_by = ["ASC", "DESC", ""]

    @deprecated_params(params_mapping={"data": None})
    def __init__(
        self, store: Optional[Union[Store, dict]] = None, logger: logging.Logger = None, **kwargs,
    ):
        self.logger = logger or logging.getLogger(__name__)
        self.getfields = kwargs.get("getfields")
        self.store = self._load_store(store)

    def _load_store(
        self, store: Union[Store, dict] = None, json_path: str = None, subquery: str = None,
    ) -> Store:
        if not store and not json_path:
            store = Store()
        if json_path:
            store = Store.from_json(json_path=json_path, subquery=subquery)
        # TODO: this should be the default structure since 0.4.0
        extract_store = store.get("extract")
        if extract_store:
            store = extract_store.get("qframe")
            self.extract_store = extract_store
        store = Store(store)
        store = self._validate_store(store)

        return store

    def from_json(self, json_path: str, subquery: str = ""):
        """Load QFrame store from JSON file.

        Parameters
        ----------
        json_path : str
            Path to local file or S3 url
        subquery : str, optional
            Key in JSON file, by default ""
        """
        self.store = self._load_store(json_path=json_path, subquery=subquery,)
        return self

    def from_dict(self, data: Union[dict, Store]):
        """Load QFrame store from Python dictionary or grizly.Store.

        Parameters
        ----------
        data : dict or Store
            Data to be loaded
        """
        self.store = self._load_store(store=data)
        return self

    def __len__(self) -> int:
        return self.nrows

    # TODO: todl
    def __getitem__(self, getfields):
        if isinstance(getfields, str):
            self.getfields = [getfields]
        elif isinstance(getfields, tuple):
            self.getfields = list(getfields)
        else:
            self.getfields = getfields
        return self

    @abstractmethod
    def to_records(self) -> List[Tuple[Any]]:
        pass

    @property
    def nrows(self) -> int:
        """Number of rows generated by QFrame's query."""
        limit = self.store.select.limit
        if limit:
            return limit
        records = self.to_records()
        return len(records)

    @property
    def data(self):
        """Alias for QFrame.store."""
        return self.store

    @property
    def ncols(self) -> int:
        """Number of columns generated by QFrame's query.

        Examples
        --------
        >>> qf.ncols
        2
        """
        ncols = len(self.get_fields())
        return ncols

    @property
    def shape(self) -> Tuple[int, int]:
        """Tuple representing number of rows and columns generated by QFrame's query."""
        nrows = self.nrows
        ncols = self.ncols
        shape = (nrows, ncols)
        return shape

    @property
    def columns(self) -> List[str]:
        """List of QFrame's columns."""
        return self.get_fields()

    @property
    def fields(self) -> List[str]:
        """Alias for QFrame.columns."""
        return self.columns

    @property
    def dtypes(self) -> List[str]:
        """List of QFrame's columns' data types."""
        return self.get_dtypes()

    # @dtypes.setter
    # def dtypes(self, new_dtypes):
    #     store_fields = self.store["select"]["fields"]
    #     if not len(new_dtypes) == len(store_fields):
    #         msg = (
    #             f"Dtypes for all fields must be provided. Got {len(new_dtypes)/len(store_fields)}."
    #         )
    #         raise ValueError(msg)
    #     for field, new_dtype in zip(store_fields, new_dtypes):
    #         field["dtype"] = new_dtype

    @property
    def types(self) -> List[str]:
        """Alias for QFrame.dtypes."""
        return self.dtypes

    def select(self, fields: List[str]):
        """TO Review: if select is dict create fields
        maybe this is not good workflow though might
        be confusing

        Parameters
        ----------
        fields : list
            List of fields to select
        """
        fields = self._get_fields_names(fields)

        for field in self.get_fields():
            if field not in fields:
                self.store["select"]["fields"].pop(field, None)
        return self

    def rename(self, fields: Dict[str, str]):
        """Rename columns (change fields' aliases).

        Parameters
        ----------
        fields : dict
            Dictionary of columns and their new names.

        Examples
        --------
        >>> qf = qf.rename({'sales': 'Billings'})
        >>> print(qf)
        SELECT "customer_id",
               "sales" AS "Billings"
        FROM grizly.sales
        """
        if not isinstance(fields, dict):
            raise ValueError("Fields parameter should be of type dict.")

        fields_names, not_found_fields = self._get_fields_names(fields, not_found=True)

        for field in not_found_fields:
            fields.pop(field)

        for field, field_nm in zip(fields.keys(), fields_names):
            self.store["select"]["fields"][field_nm]["as"] = fields[field]
        return self

    def remove(self, fields: List[str]):
        """Remove fields.

        Parameters
        ----------
        fields : list
            List of fields to remove.

        Examples
        --------
        >>> qf = qf.remove(['sales'])
        >>> print(qf)
        SELECT "customer_id"
        FROM grizly.sales
        """
        if isinstance(fields, str):
            fields = [fields]

        fields = self._get_fields_names(fields)

        for field in fields:
            self.store["select"]["fields"].pop(field, f"Field {field} not found.")

        return self

    def distinct(self):
        """Add condition to return only distinct rows.

        Examples
        --------
        >>> qf = qf.distinct()
        >>> print(qf)
        SELECT DISTINCT "customer_id",
                        "sales"
        FROM grizly.sales
        """
        self.store["select"]["distinct"] = 1

        return self

    @deprecation.deprecated(details="Use QFrame.where instead",)
    def query(self, query: str, if_exists: str = "append", operator: str = "and"):
        return self.where(query=query, if_exists=if_exists, operator=operator)

    def where(
        self,
        query: str,
        if_exists: Literal["append", "replace"] = "append",
        operator: Literal["and", "or"] = "and",
    ):
        """Add filter condition.

        Parameters
        ----------
        query : str
            Where statement.
        if_exists : {'append', 'replace'}, optional
            How to behave when the where clause already exists, by default 'append'
        operator : {'and', 'or'}, optional
            How to add another condition to existing one, by default 'and'

        Examples
        --------
        >>> qf = qf.where("sales != 0")
        >>> print(qf)
        SELECT "customer_id",
               "sales"
        FROM grizly.sales
        WHERE sales != 0
        """
        if if_exists not in ["append", "replace"]:
            raise ValueError("Invalid value in if_exists. Valid values: 'append', 'replace'.")
        if operator not in ["and", "or"]:
            raise ValueError("Invalid value in operator. Valid values: 'and', 'or'.")

        # TODO: this should be a decorator in SQLDriver
        # if "union" in self.store["select"]:
        #     self.logger.info("You can't add where clause inside union. Use select() method first.")
        # else:
        if (
            "where" not in self.store["select"]
            or self.store["select"]["where"] == ""
            or if_exists == "replace"
        ):
            self.store["select"]["where"] = query
        elif if_exists == "append":
            self.store["select"]["where"] += f" {operator} {query}"
        return self

    def having(
        self,
        having: str,
        if_exists: Literal["append", "replace"] = "append",
        operator: Literal["and", "or"] = "and",
    ):
        """Add HAVING statement.

        Parameters
        ----------
        having : str
            Having statement.
        if_exists : {'append', 'replace'}, optional
            How to behave when the having clause already exists, by default 'append'
        operator : {'and', 'or'}, optional
            How to add another condition to existing one, by default 'and'

        Examples
        --------
        >>> qf = qf.groupby(['customer_id'])['sales'].agg('sum')
        >>> qf = qf.having("sum(sales)>100")
        >>> print(qf)
        SELECT "customer_id",
               sum("sales") AS "sales"
        FROM grizly.sales
        GROUP BY 1
        HAVING sum(sales)>100
        """
        if if_exists not in ["append", "replace"]:
            raise ValueError("Invalid value in if_exists. Valid values: 'append', 'replace'.")
        if operator not in ["and", "or"]:
            raise ValueError("Invalid value in operator. Valid values: 'and', 'or'.")

        # if "union" in self.store["select"]:
        #     self.logger.info(
        #         """You can't add having clause inside union. Use select() method first.
        #     (The GROUP BY and HAVING clauses are applied to each individual query, not the final result set.)"""
        #     )

        # else:
        if (
            "having" not in self.store["select"]
            or self.store["select"]["having"] == ""
            or if_exists == "replace"
        ):
            self.store["select"]["having"] = having
        elif if_exists == "append":
            self.store["select"]["having"] += f" {operator} {having}"
        return self

    def assign(
        self,
        group_by: str = "",
        order_by: Literal["ASC", "DESC", ""] = "",
        dtype: str = "VARCHAR(500)",
        **kwargs,
    ):
        """Assign expressions.

        Parameters
        ----------
        group_by : {group, sum, count, min, max, avg, stddev ""}, optional
            Aggregation type, by default ""
        order_by : {'ASC','DESC'}, optional
            Sort ascending or descending, by default ''
        dtype : str, optional
            Column type, by default 'VARCHAR(500)'
        kwargs
            Column name is a key, value is a string.

        Examples
        --------
        >>> qf = qf.assign(sales_div="sales/100", dtype='float')
        >>> print(qf)
        SELECT "customer_id",
               "sales",
               sales/100 AS "sales_div"
        FROM grizly.sales

        >>> qf = qf.assign(sales_positive="CASE WHEN sales>0 THEN 1 ELSE 0 END", dtype='float')
        >>> print(qf)
        SELECT "customer_id",
               "sales",
               sales/100 AS "sales_div",
               CASE
                   WHEN sales>0 THEN 1
                   ELSE 0
               END AS "sales_positive"
        FROM grizly.sales
        """
        custom_type = kwargs.get("custom_type")
        _type = kwargs.get("type")
        if custom_type:
            dtype = custom_type
            self.logger.warning(
                "Parameter 'custom_type' in method QFrame.assign"
                " is deprecated as of 0.4 and will be removed"
                " in 0.4.5. Use 'dtype' instead."
            )
        elif _type:
            self.logger.warning(
                "Parameter 'type' in method QFrame.assign"
                " is deprecated as of 0.4 and will be removed"
                " in 0.4.5. Use 'dtype' instead."
            )
            if _type == "num":
                dtype = "FLOAT(53)"

        if group_by.upper() not in self._allowed_group_by:
            raise ValueError(f"Invalid value in group_by. Valid values: {self._allowed_group_by}.")
        if order_by.upper() not in self._allowed_order_by:
            raise ValueError(f"Invalid value in order_by. Valid values: {self._allowed_order_by}.")
        # if "union" in self.store["select"]:
        #     self.logger.warning(
        #         "You can't assign expressions inside union. Use select() method first."
        #     )
        # else:
        if kwargs is not None:
            for key, expression in kwargs.items():
                if key in ["custom_type", "type"]:
                    continue
                self.store["select"]["fields"][key] = {
                    "dtype": dtype,
                    "as": key,
                    "group_by": group_by,
                    "order_by": order_by,
                    "expression": expression,
                }
        return self

    def groupby(self, fields: Union[List[str], str] = None):
        """Group rows by specified fields.

        Parameters
        ----------
        fields : list or string
            List of fields or a field, if None then all fields are grouped.

        Examples
        --------
        >>> qf = qf.groupby(['customer_id'])['sales'].agg('sum')
        >>> print(qf)
        SELECT "customer_id",
               sum("sales") AS "sales"
        FROM grizly.sales
        GROUP BY 1
        """
        # assert (
        #     "union" not in self.store["select"]
        # ), "You can't group by inside union. Use select() method first."

        if isinstance(fields, str):
            fields = [fields]

        if fields is None:
            fields = self.get_fields(not_selected=True)
        else:
            fields = self._get_fields_names(fields)

        for field in fields:
            self.store["select"]["fields"][field]["group_by"] = "group"

        return self

    def agg(self, aggtype: Literal["sum", "count", "min", "max", "avg", "stddev"]):
        """Aggregate fields.

        Parameters
        ----------
        aggtype : {'sum', 'count', 'min', 'max', 'avg', 'stddev'}
            Aggregation type.

        Examples
        --------
        >>> from grizly import QFrame
        >>> qf = QFrame(dsn="redshift_acoe", schema="grizly", table="table_tutorial")
        >>> qf = qf.groupby(['col1', 'col2'])['col3', 'col4'].agg('sum')
        >>> print(qf)
        SELECT "col1",
               "col2",
               sum("col3") AS "col3",
               sum("col4") AS "col4"
        FROM grizly.table_tutorial
        GROUP BY 1,
                 2
        """
        if aggtype.upper() not in self._allowed_agg:
            raise ValueError(f"Invalid value in aggtype. Valid values: {self._allowed_agg}.")

        # if "union" in self.store["select"]:
        #     self.logger.warning("You can't aggregate inside union. Use select() method first.")
        # else:
        self.getfields = self._get_fields_names(self.getfields, aliased=False)
        for field in self.getfields:
            self.store["select"]["fields"][field]["group_by"] = aggtype

        return self

    def sum(self):
        """Sums fields that have nothing in group_by key.

        Examples
        --------
        >>> from grizly import QFrame
        >>> columns=["col1", "col2", "col3"]
        >>> qf = QFrame(dsn="redshift_acoe", schema="grizly", table="table_tutorial", columns=columns)
        >>> qf = qf.groupby(['col1']).sum()
        >>> print(qf)
        SELECT "col1",
               sum("col2") AS "col2",
               sum("col3") AS "col3"
        FROM grizly.table_tutorial
        GROUP BY 1
        """
        fields = []
        for field in self.store["select"]["fields"]:
            if self.store["select"]["fields"][field].get("group_by", "") == "":
                fields.append(field)
        return self[fields].agg("sum")

    def orderby(self, fields: Union[str, List[str]], ascending: Union[bool, List[bool]] = True):
        """Order rows by specified fields.

        Parameters
        ----------
        fields : list or str
            Fields in list or field as a string.
        ascending : bool or list, optional
            Sort ascending vs. descending. Specify list for multiple sort orders, by default True

        Examples
        --------
        >>> qf = qf.orderby(["sales"])
        >>> print(qf)
        SELECT "customer_id",
               "sales"
        FROM grizly.sales
        ORDER BY 2

        >>> qf = qf.orderby(["sales"], ascending=False)
        >>> print(qf)
        SELECT "customer_id",
               "sales"
        FROM grizly.sales
        ORDER BY 2 DESC
        """
        if isinstance(fields, str):
            fields = [fields]
        if isinstance(ascending, bool):
            ascending = [ascending for _ in fields]

        assert len(fields) == len(ascending), "Incorrect list size."

        fields = self._get_fields_names(fields)

        iterator = 0
        for field in fields:
            if field in self.store["select"]["fields"]:
                order = "ASC" if ascending[iterator] else "DESC"
                self.store["select"]["fields"][field]["order_by"] = order
            else:
                self.logger.warning(f"Field {field} not found.")

            iterator += 1

        return self

    def limit(self, limit: int):
        """Limit number of rows.

        Parameters
        ----------
        limit : int or str
            Number of rows to select.

        Examples
        --------
        >>> qf = qf.limit(100)
        >>> print(qf)
        SELECT "customer_id",
               "sales"
        FROM grizly.sales
        LIMIT 100
        """
        self.store["select"]["limit"] = str(limit)

        return self

    @property
    def _limit(self):
        try:
            return int(self.store["select"]["limit"])
        except TypeError:
            return None

    def offset(self, offset: int):
        """Skip initial rows.

        Parameters
        ----------
        offset : int or str
            Number of rows to skip before starting to return rows from query.

        Examples
        --------
        >>> qf = qf.offset(100)
        >>> print(qf)
        SELECT "customer_id",
               "sales"
        FROM grizly.sales
        OFFSET 100
        """
        self.store["select"]["offset"] = str(offset)

        return self

    def window(
        self,
        offset: int = None,
        limit: int = None,
        deterministic: bool = True,
        order_by: list = None,
    ):
        """Sort records and add LIMIT and OFFSET parameters to QFrame, creating a chunk.

        Parameters
        ----------
        offset : int, optional
            The row from which to start the data, by default None
        limit : int, optional
            Number of rows to select, by default None
        deterministic : bool, optional
            Whether the result should be deterministic, by default True
        order_by : list or str, optional
            List of fields that should be used to sort data. If None than data is sorted by all fields, by default None

        Examples
        --------
        >>> qf = qf.window(5, 10)
        >>> print(qf)
        SELECT "customer_id",
               "sales"
        FROM grizly.sales
        ORDER BY 1,
                 2
        OFFSET 5
        LIMIT 10
        """
        if deterministic:
            if order_by is not None:

                if not self.__check_if_values_are_distinct(columns=order_by):
                    raise ValueError(
                        "Selected columns don't give distinct records. Please change 'order_by' parameter or remove it."
                    )

                self.orderby(order_by)

            else:
                self.orderby(self.get_fields())

        if offset is not None:
            self.offset(offset)

        if limit is not None:
            self.limit(limit)

        return self

    def __check_if_values_are_distinct(self, columns: List[str]) -> bool:
        qf1 = self.copy()
        qf2 = self.copy()
        qf2.select(columns)
        if len(qf1.distinct()) != len(qf2.distinct()):
            return False
        return True

    def cut(self, chunksize: int, deterministic: bool = True, order_by: List[str] = None):
        """Divide a QFrame into multiple smaller QFrames, each containing chunksize rows.

        Parameters
        ----------
        chunksize : int
            Size of a single chunk.
        deterministic : bool, optional
            Whether the result should be deterministic, by default True.
        order_by : list or str, optional
            List of fields that should be used to sort data. If None than data is 
            sorted by all fields, by default None.

        Examples
        --------
        >>> from grizly import get_path, QFrame
        >>> dsn = get_path("grizly_dev", "tests", "Chinook.sqlite")
        >>> qf = QFrame(dsn=dsn, db="sqlite", dialect="mysql", table="Playlist")
        >>> qframes = qf.cut(5, order_by="PlaylistId")
        >>> len(qframes)
        4

        Returns
        -------
        list
            List of QFrames
        """
        nrows = self.__len__()
        qfs = []
        for chunk in range(0, nrows, chunksize):
            qf = self.copy()
            qf = qf.window(
                offset=chunk, limit=chunksize, deterministic=deterministic, order_by=order_by
            )
            qfs.append(qf)

        return qfs

    def rearrange(self, fields: List[str]):
        """Change order of the columns.

        Parameters
        ----------
        fields : list
            List of fields. Elements should match QFrame's fields.

        Examples
        --------
        >>> qf = qf.rearrange(['sales', 'customer_id'])
        >>> print(qf)
        SELECT "sales",
               "customer_id"
        FROM grizly.sales
        """
        if isinstance(fields, str):
            fields = [fields]

        aliased_fields = self._get_fields(aliased=True, not_selected=True)
        not_aliased_fields = self._get_fields(aliased=False, not_selected=True)

        if not set(set(aliased_fields) | set(not_aliased_fields)) >= set(fields) or len(
            not_aliased_fields
        ) != len(fields):
            raise ValueError(
                "Fields are not matching, make sure that fields are the same as in your QFrame."
            )

        fields = self._get_fields_names(fields)

        old_fields = deepcopy(self.store["select"]["fields"])
        new_fields = {}
        for field in fields:
            new_fields[field] = old_fields[field]

        self.store["select"]["fields"] = new_fields

        # self.create_sql_blocks()

        return self

    def get_fields(self, aliased: bool = False, not_selected: bool = False, **kwargs) -> List[str]:
        """Return list of QFrame's fields.

        Parameters
        ----------
        aliased : bool, optional
            Whether to return original names or aliases, by default False
        not_selected : bool, optional
            Whether to return fields that have parameter `select=0`, by default False

        Examples
        --------
        >>> qf.get_fields()
        ['customer_id', 'sales']

        Returns
        -------
        list
            List of QFrame's fields names
        """
        if not self.store:
            return []

        fields = self._get_fields(aliased=aliased, not_selected=not_selected)

        if kwargs.get("dtypes"):
            self.logger.warning(
                "Parameter dtypes in QFrame.get_dtypes is deprecated as of 0.4 and will be removed in 0.4.5."
            )
            return dict(zip(fields, self.get_dtypes()))

        return fields

    def get_dtypes(self) -> List[str]:
        """Return list of QFrame's fields data types.

        Examples
        --------
        >>> qf.get_dtypes()
        ['integer', 'double precision']

        Returns
        -------
        list
            List of QFrame's fields data types
        """
        fields = self._get_fields()
        store_fields = self.store["select"]["fields"]
        return [store_fields[field]["dtype"] for field in fields]

    def to_dict(self) -> Dict[str, list]:
        """Write QFrame's result to Python dictionary.

        Returns
        -------
        dict
            QFrame's result
        """
        _dict = {}
        columns = self.get_fields(aliased=True)
        records = self.to_records()
        for i, column in enumerate(columns):
            column_values = [
                float(line[i]) if type(line[i]) == decimal.Decimal else line[i] for line in records
            ]
            _dict[column] = column_values
        return _dict

    def to_dicts(self, chunksize: int = 20000) -> Iterator[Dict[str, Any]]:
        # requires subclass to implement to_records_iter()
        columns = self.get_fields(aliased=True)
        chunks = self.to_records_iter(chunksize=chunksize)
        for chunk in chunks:
            _dict = {}
            for i, column in enumerate(columns):
                column_values = [
                    float(line[i]) if type(line[i]) == decimal.Decimal else line[i]
                    for line in chunk
                ]
                _dict[column] = column_values
            yield _dict

    @deprecated_params({"chunksize": None, "verbose": None})
    def to_df(self, **kwargs) -> DataFrame:
        """Write QFrame's result to pandas.DataFrame.

        Returns
        -------
        DataFrame
            QFrame's result
        """
        self.logger.debug("Generating pandas DataFrame...")
        d = self.to_dict()
        df = DataFrame(d)
        self.logger.debug("Pandas DataFrame has been generated successfully")

        return df

    def _dict_to_arrow(self, _dict):
        self.logger.debug("Generating PyArrow table...")
        self._fix_types()

        columns = self.get_fields(aliased=True)
        types_mapped = self.source.map_types(self.get_dtypes(), to="pyarrow")
        schema = pa.schema([pa.field(name, dtype) for name, dtype in zip(columns, types_mapped)])

        self.logger.debug(f"Retrieved schema: {schema}")

        table = pa.Table.from_pydict(_dict, schema=schema)

        self.logger.debug("PyArrow table has been generated successfully")

        return table

    def to_arrow(self) -> pa.Table:
        """Write QFrame's result to pyarrow.Table.

        Returns
        -------
        pa.Table
            QFrame's result
        """

        self.logger.debug("Generating PyArrow table...")
        self._fix_types()
        columns = self.get_fields(aliased=True)
        types_mapped = self.source.map_types(self.get_dtypes(), to="pyarrow")
        schema = pa.schema([pa.field(name, dtype) for name, dtype in zip(columns, types_mapped)])
        self.logger.debug(f"Retrieved schema: {schema}")

        _dict = self.to_dict()
        table = pa.Table.from_pydict(_dict, schema=schema)
        self.logger.debug("PyArrow table has been generated successfully")

        gc.collect()

        return table

    def to_arrow_iter(self, chunksize: int = 20000) -> Iterator[pa.Table]:
        """Write QFrame result to pyarrow.Table.

        Returns
        -------
        pa.Table
            QFrame's result
        """
        self.logger.debug("Generating PyArrow table...")
        self._fix_types()
        columns = self.get_fields(aliased=True)
        types_mapped = self.source.map_types(self.get_dtypes(), to="pyarrow")
        schema = pa.schema([pa.field(name, dtype) for name, dtype in zip(columns, types_mapped)])
        self.logger.debug(f"Retrieved schema: {schema}")

        dicts = self.to_dicts(chunksize=chunksize)
        for _dict in dicts:
            table = pa.Table.from_pydict(_dict, schema=schema)
            yield table

    @deprecated_params(params_mapping={"parquet_path": "path"})
    def to_parquet(self, path: str, **kwargs) -> bool:
        """Write QFrame result to PARQUET file.

        Parameters
        ----------
        path : str
            Path to PARQUET file.

        Returns
        -------
        bool
            True if the result was saved successfully in the file
        """
        # NOTE: self.source has to have map_types(to="python") method defined

        arrow_table = self.to_arrow()
        root_path = os.path.dirname(path) or os.getcwd()
        file_name = os.path.basename(path)

        self.logger.info(f"Writing {file_name} to {root_path}...")

        if path.startswith("s3://"):
            filesystem = s3fs.S3FileSystem()
        else:
            filesystem = None

        pq.write_to_dataset(
            arrow_table,
            root_path=root_path,
            filesystem=filesystem,
            partition_filename_cb=lambda x: file_name,
        )

        self.logger.info(f"Successfully wrote {file_name} to {root_path}")

        return True

    def to_crosstab(self, dimensions: List[str], measures: List[str], **ct_kwargs) -> Crosstab:
        """Write QFrame's records to grizly.Crosstab.

        Parameters
        ----------
        dimensions : list
            List of dimensions columns
        measures : list
            List of numeric columns
        **ct_kwargs
            Additional keyword arguments passed to `grizly.Crosstab`

        Returns
        -------
        Crosstab
            QFrame's result
        """
        df = self.to_df()
        self.logger.debug("Generating grizly Crosstab...")
        ct = Crosstab(logger=self.logger, **ct_kwargs).from_df(
            df=df, dimensions=dimensions, measures=measures
        )
        self.logger.debug("Grizly Crosstab has been generated successfully")

        return ct

    @deprecated_params({"chunksize": None, "debug": None})
    def to_csv(self, csv_path: str, sep: str = "\t", **kwargs):
        """Write QFrame's result to CSV file.

        Parameters
        ----------
        csv_path : str
            Path to csv file
        sep : str, optional
            Separator/delimiter in csv file, by default "\t"
        """
        columns = self.get_fields(aliased=True)
        records = self.to_records()

        self.logger.info(f"Writing data into '{os.path.basename(csv_path)}'...")

        with open(csv_path, "w", newline="", encoding="utf-8") as csvfile:
            writer = csv.writer(csvfile, delimiter=sep)
            writer.writerow(columns)
            writer.writerows(records)

        self.logger.info(f"Successfully wrote to '{os.path.basename(csv_path)}'")

    def to_excel(
        self,
        input_excel_path: str = None,
        output_excel_path: str = None,
        index: bool = False,
        header: bool = True,
        **pd_kwargs,
    ):
        """Write QFrame's result to Excel file.

        Parameters
        ----------
        input_excel_path : str
            Path to template Excel file, by default 'grizly_test.xlsx'
        output_excel_path : str
            Path to Excel file in which we want to save data, if None then input_excel_path
        index : bool, optional
            Write row index, by default False
        header : bool, optional
            Write header, by default False
        **pd_kwargs
            Additional keyword arguments passed to `pandas.DataFrame.to_excel`
        """
        input_excel_path = input_excel_path or "grizly_test.xlsx"
        output_excel_path = output_excel_path or input_excel_path
        df = self.to_df()

        self.logger.info(f"Writing data into '{os.path.basename(output_excel_path)}'...")
        copy_df_to_excel(
            df=df,
            input_excel_path=input_excel_path,
            output_excel_path=output_excel_path,
            index=index,
            header=header,
            **pd_kwargs,
        )
        self.logger.info(f"Successfully wrote to '{os.path.basename(output_excel_path)}'")

    def copy(self):
        """Make a copy of QFrame."""
        return deepcopy(self)

    def _fix_types(self):
        mismatched: dict = self._check_types()
        mismatched_aliases = list(mismatched.keys())
        mismatched_names = self._get_fields_names(mismatched_aliases)
        for field_name, field_alias in zip(mismatched_names, mismatched_aliases):
            python_dtype = mismatched[field_alias]
            sql_dtype = python_to_sql(python_dtype)
            self.store["select"]["fields"][field_name]["dtype"] = sql_dtype

    def _check_types(self):
        expected_types_mapped = self.source.map_types(self.dtypes, to="python")
        expected_cols_and_types = dict(zip(self.get_fields(aliased=True), expected_types_mapped))
        # this only checks the first 100 rows
        retrieved_cols_and_types = {}
        sample = self.copy().limit(100)
        d = sample.to_dict()
        for col in d:
            unique_types = {type(val) for val in d[col] if val is not None}
            if len(unique_types) > 1:
                raise NotImplementedError(
                    f"Multiple types detected in {col}: {unique_types}. This is not yet handled."
                )
            if not unique_types:
                unique_types = {type(None)}
            retrieved_cols_and_types[col] = list(unique_types)[0]
        mismatched_with_none = dict_diff(
            expected_cols_and_types, retrieved_cols_and_types, by="values"
        )
        mismatched = {
            col: dtype for col, dtype in mismatched_with_none.items() if dtype is not type(None)
        }
        return mismatched

    def _get_fields_names(
        self, fields, aliased=False, not_found=False
    ) -> Union[List[str], Tuple[List[str]]]:
        """Returns a list of fields keys or fields aliases.
        Input parameters 'fields' can contain both aliased and not aliased fields

        not_found - whether to return not found fields"""
        # TODO: TO BE REFACTORED

        not_aliased_fields = self._get_fields_key_names(not_selected=True)
        aliased_fields = self._get_fields_aliases(not_selected=True)

        not_found_fields = []
        output_fields = []

        if aliased:
            for field in fields:
                if field in aliased_fields:
                    output_fields.append(field)
                elif field in not_aliased_fields:
                    output_fields.append(aliased_fields[not_aliased_fields.index(field)])
                else:
                    not_found_fields.append(field)
        else:
            for field in fields:
                if field in not_aliased_fields:
                    output_fields.append(field)
                elif field in aliased_fields:
                    output_fields.append(not_aliased_fields[aliased_fields.index(field)])
                else:
                    not_found_fields.append(field)

        if not_found_fields:
            self.logger.warning(f"Fields {not_found_fields} not found.")

        return output_fields if not not_found else (output_fields, not_found_fields)

    def _get_fields(self, aliased=False, not_selected=False):
        if aliased:
            return self._get_fields_aliases(not_selected=not_selected)
        else:
            return self._get_fields_key_names(not_selected=not_selected)

    def _get_fields_aliases(self, not_selected=False):
        """Return list of fields aliases (field["as"] or field key name)"""
        fields_data = self.store["select"]["fields"]
        fields_out = []

        for field in fields_data:
            if (
                not not_selected
                and "select" in fields_data[field]
                and fields_data[field]["select"] == 0
            ):
                continue
            else:
                alias = (
                    field
                    if "as" not in fields_data[field] or fields_data[field]["as"] == ""
                    else fields_data[field]["as"]
                )
                fields_out.append(alias)

        return fields_out

    def _get_fields_key_names(self, not_selected=False):
        """Return list of keys in store["select"]["fields"]"""
        fields_data = self.store["select"]["fields"]
        fields_out = []

        for field in fields_data:
            if (
                not not_selected
                and "select" in fields_data[field]
                and fields_data[field]["select"] == 0
            ):
                continue
            else:
                fields_out.append(field)

        return fields_out

    def show_duplicated_columns(self):
        """Show QFrame's duplicated columns."""
        duplicates = self._get_duplicated_columns()

        if duplicates != {}:
            print("\033[1m", "DUPLICATED COLUMNS: \n", "\033[0m")
            for key in duplicates.keys():
                print(f"{key}:\t {duplicates[key]}\n")
            print("Use your_qframe.remove() to remove or your_qframe.rename() to rename columns.")

        else:
            self.logger.info("There are no duplicated columns.")

    def _get_duplicated_columns(self):
        columns = {}
        fields = self.store["select"]["fields"]

        for field in fields:
            alias = (
                field
                if "as" not in fields[field] or fields[field]["as"] == ""
                else fields[field]["as"]
            )
            if alias in columns.keys():
                columns[alias].append(field)
            else:
                columns[alias] = [field]

        duplicates = deepcopy(columns)
        for alias in columns.keys():
            if len(columns[alias]) == 1:
                duplicates.pop(alias)

        return duplicates

    def _validate_store(self, store: Store) -> None:
        """Validate loaded data.

        Parameters
        ----------
        store : Store
            Store holding fields, schema, table, sql information.

        Returns
        -------
        Store
            Store with validated data.
        """
        store = deepcopy(store)

        if not store:
            return

        if not store.get("select"):
            raise AttributeError("Missing 'select' attribute.")

        select_data = store["select"]

        if not select_data.get("fields"):
            raise AttributeError("Missing 'fields' attribute.")

        fields = select_data["fields"]

        for field_name, field_data in fields.items():
            self._validate_field(field=field_name, data=field_data)

        validations = {
            "distinct": lambda x: str(x) == "1",
            "offset": lambda x: str(x).isdigit(),
            "limit": lambda x: str(x).isdigit(),
        }
        for key, validate_func in validations.items():
            self._validate_key(
                key=key, data=select_data, func=validate_func,
            )

        return store

    def _validate_field(self, field: str, data: dict):
        if "dtype" not in data:
            self.__adjust_field_type(field, data)

        validations = {
            "dtype": lambda x: isinstance(x, str),
            "group_by": lambda x: x.upper() in self._allowed_group_by,
            "order_by": lambda x: x.upper() in self._allowed_order_by,
            "select": lambda x: str(x) == "0",
        }
        for key, validate_func in validations.items():
            self._validate_key(
                key=key, data=data, func=validate_func,
            )

    def __adjust_field_type(self, field: str, data: dict):
        """Replace 'custom_type' and 'type' with 'dtype' key"""
        if "custom_type" in data and data["custom_type"] != "":
            dtype = data["custom_type"].upper()
        elif data["type"] == "num":
            dtype = "FLOAT(53)"
        else:
            dtype = "VARCHAR(500)"
        data["dtype"] = dtype
        data.pop("custom_type", None)
        data.pop("type", None)
        self.logger.warning(
            f"Missing 'dtype' key in field '{field}'. "
            "Since version 0.4 of grizly uses 'dtype' key instead "
            "of 'type' and 'custom_type' keys. To update your "
            "json file please use qf.store.to_json() method."
        )

    @staticmethod
    def _validate_key(key: str, data: dict, func: Callable):

        if key in data and data[key] != "":
            value = data[key]
            if not func(value):
                raise ValueError(f"""Invalid value in {key}: '{value}'""")

    @staticmethod
    def _build_store(columns: List[str], dtypes: List[str]):
        """Create a dictionary with fields information for a Qframe

        Parameters
        ----------
        columns : list
            List of columns.
        dtypes : list
            List of data types of columns
        """
        if columns == []:
            return {}

        fields = {}

        for col, dtype in zip(columns, dtypes):
            field = {
                "as": "",
                "dtype": dtype,
                "group_by": "",
                "order_by": "",
                "select": "",
                "expression": "",
            }
            fields[col] = field

        data = {
            "select": {
                "fields": fields,
                "where": "",
                "distinct": "",
                "having": "",
                "offset": "",
                "limit": "",
            }
        }

        return Store(data)
