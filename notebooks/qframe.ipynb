{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a QFrame\n",
    "\n",
    "The best way to create a QFrame from scratch is to first create a `store.jon` file using Store(). This way you can build an initial structure for your work.\n",
    "\n",
    "You can create a `store.json` with the below code. Refer to the Store tutorial here on the left if you want to learn more about this functionality. For now we will focus on QFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grizly import Store, get_path, QFrame, union\n",
    "from grizly import get_path\n",
    "\n",
    "json_path = get_path(\"acoe_projects\",\"dev\", \"grizly\",\n",
    "                            \"notebooks\",\"store.json\")\n",
    "store = Store(json_path)\n",
    "store.add_query([\"col1\", \"col2\"], \"schema\", \"table\", \"query_xyz\")\n",
    "store.to_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great!** So now we have a `store.json` file created, we want to create a QFrame. Let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf = QFrame().read_json(json_path=json_path, subquery=\"query_xyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the QFrame\n",
    "\n",
    "#### Getting the sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2622ea413cc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mqf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'qf' is not defined"
     ]
    }
   ],
   "source": [
    "qf.get_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing some basic SQL stuff\n",
    "\n",
    "The above code should generate the query below. This is a very simple query but you can see that this was created from your `store.json` file.\n",
    "```sql\n",
    "SELECT col1,\n",
    "       col2\n",
    "FROM schema.table\n",
    "```\n",
    "\n",
    "Now let's add a `where` statement, a `limit` and a `calculated` field all in 1 go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf.query(\"col2 = 'some col2 value'\") #<- where\n",
    "qf.limit(10)\n",
    "qf.assign(calculated_field = \"col2*2\")\n",
    "qf.get_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will generate the below sql. We have quickly generated a query with some of the most commonly used sql statements.\n",
    "\n",
    "```sql\n",
    "SELECT col1,\n",
    "       col2,\n",
    "       col2*2 AS calculated_field\n",
    "FROM schema.table\n",
    "WHERE col2 = 'some col2 value'\n",
    "  AND col2 = 'some col2 value'\n",
    "LIMIT 10\n",
    "```\n",
    "\n",
    "As we update the `qf` object we are updated the `qf.data` variable which is a normal python dictionary. Go ahead and check what happens if you do `print(qf.data)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forking\n",
    "\n",
    "Forking qframes can be important if your data workflow needs to take the same sql table and apply different transformations to it.\n",
    "\n",
    "Sometimes we want to fork, do some transforms, then union the qframes back together which results into an append operation on the data side.\n",
    "\n",
    "By the way the return value of `union()` is also a qframe and if you do `uqf.get_sql()` below you get\n",
    "\n",
    "```sql\n",
    "SELECT col1,\n",
    "       col2\n",
    "FROM schema.table\n",
    "UNION ALL\n",
    "SELECT col1,\n",
    "       col2\n",
    "FROM schema.table\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf2 = qf.copy() #<- forking\n",
    "uqf = union(qframes=[qf, qf2], union_type=\"UNION ALL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining data\n",
    "\n",
    "Unioning data is easy and described in the paragraph above. Joining data is equally easy, but we need to pay attention to the `on` argument.\n",
    "\n",
    "First off, here is the SQL code generated by the below python code:\n",
    "\n",
    "```sql\n",
    "SELECT sq1.col1 AS col1,\n",
    "       sq1.col2 AS col2\n",
    "FROM\n",
    "  (SELECT col1,\n",
    "          col2\n",
    "   FROM schema.table) sq1 INNER\n",
    "  (SELECT col1,\n",
    "          col2\n",
    "   FROM schema.table) sq2 ON 'sq1.col1' = 'sq2.col1'\n",
    "```\n",
    "\n",
    "As you can see the expression after `ON` is exactly the same as the expression the user puts in the `on` value of the `join()` argument. It is key to remember to add `sq1` for the first qframe in `qframes` and `sq2` for the second\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grizly import join\n",
    "\n",
    "jq = join(qframes=[qf, qf2], join_type=\"INNER\", on=\"'sq1.col1' = 'sq2.col1'\")\n",
    "\n",
    "jq.get_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the store.json\n",
    "\n",
    "We use a `.json` file to conviniently manipulate information about columns, renames and other things that might be very verbose to manipulate in python code. We can edit the json file into a json editor like http://jsoneditoronline.org/ more conviniently than in Python code.\n",
    "\n",
    "After editing the `store.json` we can read it back inside a QFrame using `read_json()`.\n",
    "\n",
    "This means we can use our json as our main `store` of verbose information and python as our main way to manipulate said information.\n",
    "\n",
    "This is how the structure of an sql query looks like in `store.js`:\n",
    "\n",
    "```json\n",
    "\"sales_flash\": {\n",
    "    \"select\": {\n",
    "    \"fields\": {\n",
    "        \"dimension_column_1\": {\n",
    "        \"type\": \"dim\",\n",
    "        \"group_by\": \"group\"\n",
    "        },\n",
    "        \"value_column_1\": {\n",
    "        \"type\": \"dim\",\n",
    "        \"as\": \"some as name\",\n",
    "        \"group_by\": \"sum\"\n",
    "        }\n",
    "    },\n",
    "    \"schema\": \"schema\",\n",
    "    \"where\": \"dimension_column_1='abc'\"\n",
    "    \"table\": \"table\",\n",
    "    \"limit\": 10\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "We have there:\n",
    "\n",
    "* The key or subquery name `sales_flash`\n",
    "* The `select`, here we have all the information to generate the sql\n",
    "* The `select.fields` all field type information\n",
    "* The `schema`, the `table`, the `limit` and the `where`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In database workflow\n",
    "\n",
    "Sometimes all the data is in 1 database. Like for instance it is all in Redshift.\n",
    "\n",
    "In this case we want to materialize the new transformed data inside a new Redshift table. This will make our workflow a lot faster as the data will not need to come back to our desktop and then uploaded again into the database.\n",
    "\n",
    "We need to keep in mind a couple of things. First, we need to make sure to run to_sql() on the qframe, this way grizly will generate the internal sql necessary to create the table. Second, we need to create the table. Finally we can upload the qframe sql into our new table. Note, if the table already exists we donâ€™t need to run get_sql or create_table.\n",
    "\n",
    "```python\n",
    "from grizly import set_cwd, QFrame\n",
    "json = set_cwd(\"acoe_projects\", \"training\", \"subquery.json\")\n",
    "qf = QFrame(engine=\"mssql+pyodbc://Redshift\").read_json(json_path = json, subquery=\"sandbox\")\n",
    "qf.get_sql()\n",
    "qf.create_table(\"testing2\", schema=\"z_sandbox_ac\")\n",
    "qf.to_table(table = \"testing2\", schema = \"z_sandbox_ac\", if_exists=\"replace\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
