{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove this and queries.json when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas\n",
    "from grizly import QFrame, S3, Workflow\n",
    "import dask\n",
    "from distributed import Client, fire_and_forget\n",
    "from sqlalchemy import create_engine\n",
    "import cx_Oracle\n",
    "\n",
    "@dask.delayed\n",
    "def clean_s3_table(table, s3_key):\n",
    "    s3 = S3(s3_key=s3_key)\n",
    "    for file_name in s3.list():\n",
    "        S3(file_name=file_name, s3_key=s3_key, bucket=\"acoe-s3\").delete()\n",
    "\n",
    "@dask.delayed\n",
    "def get_downloaded_partitions(qf, logger):\n",
    "    table = qf.data[\"select\"][\"table\"].lower()\n",
    "    logger.info(\"starting_ extract process\")\n",
    "    s3 = S3(s3_key=f\"data_loads/inventory/{table}\")\n",
    "    downloaded_partitions = []\n",
    "    for item in s3.list():\n",
    "        items = item.split(\".\")\n",
    "        if items[1]==\"parquet\":\n",
    "            downloaded_partitions.append(items[0].split(\"_\")[1])\n",
    "    logger.info(\"denodo  get_downloaded_partitions() done\")\n",
    "    return downloaded_partitions\n",
    "\n",
    "@dask.delayed\n",
    "def get_partitions(qf, downloaded_partitions, partition_column):\n",
    "    _qf = qf.copy()\n",
    "    _qf.select([partition_column])\n",
    "    _qf.assign(partition_column=\"sq.\" + partition_column)\n",
    "    _qf.groupby([f\"sq.{partition_column}\", \"partition_column\" ])[f\"sq.{partition_column}\"].agg(\"count\")\n",
    "    df = _qf.to_df()\n",
    "    l = []\n",
    "    for partition in df[\"partition_column\"]:\n",
    "        if partition not in downloaded_partitions:\n",
    "            #l.append(\"'\"+partition+\"'\")\n",
    "            l.append(partition)\n",
    "    logger.info(\"denodo  get_partitions() done\")\n",
    "    return l\n",
    "\n",
    "@dask.delayed\n",
    "def to_parquet(qf, partition_column, partitions_to_download, downloads_path, fillna={}):\n",
    "    table = qf.data[\"select\"][\"table\"].lower()\n",
    "    s3_key=f'data_loads/inventory/{table}'\n",
    "    if partitions_to_download == []:\n",
    "        logger.info(\"Done. No more partitions to download\")\n",
    "        return \"done\"\n",
    "    else:\n",
    "        for partition in  partitions_to_download:\n",
    "            _qf = qf.copy()\n",
    "            logger.info(f\"extracting table {table} for {partition_column} {partition} in {s3_key}\")\n",
    "            partition_id = partition.replace(\"'\",\"\")\n",
    "            file_name = f\"{partition_column}_{partition_id}.parquet\"\n",
    "            where = f\"{partition_column}='{partition}'\"\n",
    "            _qf.query(where)\n",
    "            logger.info(_qf.get_sql())\n",
    "            df = _qf.to_df()\n",
    "            df.fillna(fillna).to_parquet(downloads_path+\"/\"+file_name)\n",
    "            if not df.empty:\n",
    "                logger.info(f'data_loads/inventory/{table}')\n",
    "                s3 = S3(file_name = file_name, s3_key=s3_key\n",
    "                        , file_dir=downloads_path).from_file(keep_file=False)\n",
    "            else:\n",
    "                logger.info(df)\n",
    "        logger.info(f'all loaded data_loads/inventory/{table}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "from distributed import Client, fire_and_forget, Future\n",
    "\n",
    "from grizly import QFrame, Workflow\n",
    "\n",
    "def run_job(json_path, subquery, reload=False):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        job = json.load(f)[subquery]\n",
    "\n",
    "    logger = logging.getLogger(\"distributed.worker.extract.\" + subquery)\n",
    "    client = Client(job[\"workflow\"][\"ip\"])\n",
    "    \n",
    "    qf = QFrame(engine=job[\"origin\"][\"engine\"]\n",
    "               ).from_json(json_path, subquery)\n",
    "    fillna = {field:\"NoValue\" for field in qf.get_fields()}\n",
    "    \n",
    "    s3_key = job[\"destination\"][\"s3_root\"]+job[\"destination\"][\"table\"]\n",
    "    \n",
    "    if reload:\n",
    "        reloaded = clean_s3_table(table, s3_key)\n",
    "    else:\n",
    "        reloaded = \"\"\n",
    "        \n",
    "    downloaded_partitions = get_downloaded_partitions(qf, logger)\n",
    "    uploads = [downloaded_partitions]\n",
    "\n",
    "    wf = Workflow(\n",
    "            subquery,\n",
    "            owner_email=\"acivitillo@te.com\",\n",
    "            backup_email=\"marcin.socha@te.com\",\n",
    "            tasks=uploads,\n",
    "            priority=0,\n",
    "        )\n",
    "    wf.submit(client)\n",
    "    \n",
    "def kill_job(subquery):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        job = json.load(f)[subquery]\n",
    "    client = Client(job[\"workflow\"][\"ip\"])\n",
    "    f = Future(f\"{subquery}_graph\", client=client)\n",
    "    f.cancel(force=True)\n",
    "    client.close()\n",
    "\n",
    "        \n",
    "json_path = \"/home/analyst/grizly/notebooks/queries.json\"\n",
    "subquery = \"planned_indp\"\n",
    "run_job(json_path, subquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill_job(subquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'planned_indp': {'destination': {'download_path': '/home/analyst/data_loads',\n",
       "   's3_key': 'ac_testing/loads/',\n",
       "   'table': 'table',\n",
       "   'schema': 'schema'},\n",
       "  'origin': {'engine': 'mssql+pyodbc://denodo_dev', 'type': 'odbc'},\n",
       "  'workflow': {'ip': 'acoe.connect.te.com:8786',\n",
       "   'partition_column': 'plant',\n",
       "   'owner_email': 'acivitillo@te.com',\n",
       "   'backup_email': 'marcin.socha@te.com'},\n",
       "  'select': {'table': 'PLANNED_INDP_REQR_FORECASTS_V',\n",
       "   'fields': {'material_number': {'type': 'dim',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': ''},\n",
       "    'plant': {'type': 'dim',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': ''},\n",
       "    'requirements_type': {'type': 'dim',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': ''},\n",
       "    'requirements_version': {'type': 'dim',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': ''},\n",
       "    'indicator_active_version': {'type': 'dim',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': ''},\n",
       "    'unconsumed_qty_period_bucket_1': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket_2': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket_3': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket_4': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket_5': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket_6': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket_7': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket_8': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket_9': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket10': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket11': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket12': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket13': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket14': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket15': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket16': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket17': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'},\n",
       "    'unconsumed_qty_period_bucket18': {'type': 'num',\n",
       "     'as': '',\n",
       "     'group_by': '',\n",
       "     'order_by': '',\n",
       "     'expression': '',\n",
       "     'select': '',\n",
       "     'custom_type': 'BIGINT'}},\n",
       "   'engine': '',\n",
       "   'where': '',\n",
       "   'distinct': '',\n",
       "   'having': '',\n",
       "   'offset': '',\n",
       "   'limit': ''}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = Client(\"acoe.connect.te.com:8786\")\n",
    "\n",
    "subquery = \"planned_indp\"\n",
    "partition_column = \"plant\"\n",
    "fillna = {\"indicator_active_version\":\"NoValue\"}\n",
    "\n",
    "root = \"/home/analyst/inventory\"\n",
    "downloads_path=f\"/home/analyst/data_loads\"\n",
    "qf = QFrame(engine=\"mssql+pyodbc://denodo_dev\"\n",
    "           ).from_json(os.path.join(root, \"queries.json\"), subquery=subquery)\n",
    "table = qf.data[\"select\"][\"table\"].lower()\n",
    "s3_key=f\"data_loads/inventory/{table}\"\n",
    "\n",
    "done = clean_s3_table(table, s3_key)\n",
    "downloaded_partitions = get_downloaded_partitions(qf)\n",
    "partitions_to_download = get_partitions(qf, downloaded_partitions, partition_column)\n",
    "parquets = to_parquet(qf, partition_column, partitions_to_download, downloads_path, fillna)\n",
    "\n",
    "#uploads = [done]\n",
    "uploads = [parquets]\n",
    "\n",
    "wf = Workflow(\n",
    "        subquery,\n",
    "        owner_email=\"acivitillo@te.com\",\n",
    "        backup_email=\"marcin.socha@te.com\",\n",
    "        tasks=uploads,\n",
    "        priority=0,\n",
    "    )\n",
    "wf.submit(client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
