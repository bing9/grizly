{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "from boto3 import resource\n",
    "\n",
    "from grizly.scheduling.registry import Job\n",
    "from grizly import Email, S3, config\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GRIZLY_REDIS_HOST\"] = \"10.125.68.177\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you register a job you have to define function that your job will run. Let's define a function that returns last modified date of a file in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_modified_date():\n",
    "    bucket = \"acoe-s3\"\n",
    "    date = resource(\"s3\").Object(bucket, \"grizly/test_scheduling.csv\").last_modified\n",
    "    return str(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jobs that are listening for some changes are called **listener jobs**. A good practice is to end their name with `listener` suffix so that they are easy to list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:22:38,207 - grizly.scheduling.registry - INFO - Job s3_grizly_test_scheduling_listener successfully removed from registry\n",
      "2020-12-10 17:22:39,146 - grizly.scheduling.registry - INFO - Job s3_grizly_test_scheduling_listener successfully registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Job(name='s3_grizly_test_scheduling_listener')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = Job(\"s3_grizly_test_scheduling_listener\")\n",
    "\n",
    "job.register(func=get_last_modified_date, \n",
    "             if_exists=\"replace\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just registered a job called `s3_grizly_test_scheduling_listener`. The name of the job is unique and you can always check its details with `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: s3_grizly_test_scheduling_listener\n",
      "owner: None\n",
      "description: None\n",
      "timeout: 3600\n",
      "created_at: 2020-12-10 17:22:38.209627+00:00\n",
      "crons: []\n",
      "downstream: {}\n",
      "upstream: {}\n",
      "triggers: []\n"
     ]
    }
   ],
   "source": [
    "job = Job(\"s3_grizly_test_scheduling_listener\")\n",
    "\n",
    "job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this job is not scheduled yet - it's not a cron job and it doesn't have any upstream jobs and it doesn't have any triggers. You can pass these parameters during registration or overwrite them later using `crons`, `upstream` or `triggers` attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add cron string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add now a cron string to our job to run every two hours. You can generate cron string using this website https://crontab.guru/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: s3_grizly_test_scheduling_listener\n",
      "owner: None\n",
      "description: None\n",
      "timeout: 3600\n",
      "created_at: 2020-12-10 17:22:38.209627+00:00\n",
      "crons: ['0 */2 * * *']\n",
      "downstream: {}\n",
      "upstream: {}\n",
      "triggers: []\n"
     ]
    }
   ],
   "source": [
    "job.crons = \"0 */2 * * *\"\n",
    "\n",
    "job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run your job imediately using `submit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:22:49,912 - grizly.scheduling.registry - INFO - Submitting job s3_grizly_test_scheduling_listener...\n",
      "2020-12-10 17:22:51,572 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2020-12-10 17:22:55,667 - grizly.scheduling.registry - INFO - Job s3_grizly_test_scheduling_listener finished with status success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2020-12-10 17:21:22+00:00'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.submit(scheduler_address=\"10.125.68.177:8999\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check job's last run details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first run you will be able to access `last_run` property with information about the last run of your job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\n",
      "name: None\n",
      "created_at: 2020-12-10 17:22:50.261603+00:00\n",
      "finished_at: 2020-12-10 17:22:55.668267+00:00\n",
      "duration: 4\n",
      "status: success\n",
      "error: None\n",
      "result: 2020-12-10 17:21:22+00:00\n"
     ]
    }
   ],
   "source": [
    "job.last_run.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now update the file and run the job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:23:02,719 - grizly.sources.filesystem.old_s3 - INFO - Successfully uploaded 'test_scheduling.csv' to S3\n"
     ]
    }
   ],
   "source": [
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = DataFrame(data=d)\n",
    "\n",
    "s3 = S3(s3_key=\"grizly/\", file_name=\"test_scheduling.csv\").from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:23:04,934 - grizly.scheduling.registry - INFO - Submitting job s3_grizly_test_scheduling_listener...\n",
      "2020-12-10 17:23:10,431 - grizly.scheduling.registry - INFO - Job s3_grizly_test_scheduling_listener finished with status success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2020-12-10 17:23:03+00:00'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.submit(scheduler_address=\"10.125.68.177:8999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 2\n",
      "name: None\n",
      "created_at: 2020-12-10 17:23:05.253426+00:00\n",
      "finished_at: 2020-12-10 17:23:10.432068+00:00\n",
      "duration: 4\n",
      "status: success\n",
      "error: None\n",
      "result: 2020-12-10 17:23:03+00:00\n"
     ]
    }
   ],
   "source": [
    "job.last_run.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register jobs with upstream job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now register two jobs with upstream job `s3_grizly_test_scheduling_listener`. One will send an email whenever upstream finished with status `success` and the other will send an email whenever the upstream changed his result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email(subject, body, to):\n",
    "    logger = logging.getLogger(\"grizly\").getChild(\"email\")\n",
    "    e = Email(subject=subject, body=body, logger=logger)\n",
    "    e.send(to=to)\n",
    "    \n",
    "to = config.get_service(\"email\").get(\"address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:23:18,627 - grizly.scheduling.registry - INFO - Job email_upstream_success successfully registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: email_upstream_success\n",
      "owner: None\n",
      "description: None\n",
      "timeout: 3600\n",
      "created_at: 2020-12-10 17:23:15.796617+00:00\n",
      "crons: []\n",
      "downstream: {}\n",
      "upstream: {'s3_grizly_test_scheduling_listener': 'success'}\n",
      "triggers: []\n"
     ]
    }
   ],
   "source": [
    "job = Job(\"email_upstream_success\")\n",
    "\n",
    "job.register(func=send_email, \n",
    "             subject=\"Job success\",\n",
    "             body=\"Job `s3_grizly_test_scheduling_listener` finished with status success.\", \n",
    "             to=to,\n",
    "             if_exists=\"replace\",\n",
    "             upstream={\"s3_grizly_test_scheduling_listener\": \"success\"}\n",
    "             )\n",
    "\n",
    "job.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:23:24,944 - grizly.scheduling.registry - INFO - Job email_upstream_result_change successfully registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: email_upstream_result_change\n",
      "owner: None\n",
      "description: None\n",
      "timeout: 3600\n",
      "created_at: 2020-12-10 17:23:22.105970+00:00\n",
      "crons: []\n",
      "downstream: {}\n",
      "upstream: {'s3_grizly_test_scheduling_listener': 'result_change'}\n",
      "triggers: []\n"
     ]
    }
   ],
   "source": [
    "job = Job(\"email_upstream_result_change\")\n",
    "\n",
    "job.register(func=send_email, \n",
    "             subject=\"File changed\",\n",
    "             body=\"Somebody changed 'grizly/test_scheduling.csv' file!\", \n",
    "             to=to,\n",
    "             if_exists=\"replace\",\n",
    "             upstream={\"s3_grizly_test_scheduling_listener\": \"result_change\"}\n",
    "            )\n",
    "\n",
    "job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see now that `s3_grizly_test_scheduling_listener` has two downstream jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: s3_grizly_test_scheduling_listener\n",
      "owner: None\n",
      "description: None\n",
      "timeout: 3600\n",
      "created_at: 2020-12-10 17:22:38.209627+00:00\n",
      "crons: ['0 */2 * * *']\n",
      "downstream: {'email_upstream_success': 'success', 'email_upstream_result_change': 'result_change'}\n",
      "upstream: {}\n",
      "triggers: []\n"
     ]
    }
   ],
   "source": [
    "job = Job(\"s3_grizly_test_scheduling_listener\")\n",
    "job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now submit the listener job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:23:32,821 - grizly.scheduling.registry - INFO - Submitting job s3_grizly_test_scheduling_listener...\n",
      "2020-12-10 17:23:38,143 - grizly.scheduling.registry - INFO - Job s3_grizly_test_scheduling_listener finished with status success\n",
      "2020-12-10 17:23:43,995 - grizly.scheduling.registry - INFO - Job email_upstream_success has been enqueued\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2020-12-10 17:23:03+00:00'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.submit(scheduler_address=\"10.125.68.177:8999\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see `s3_grizly_test_scheduling_listener` job finished with status success and enqueued his downstream job `email_upstream_succcess`. Let's now change the file in s3 and run our listener job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:23:47,104 - grizly.sources.filesystem.old_s3 - INFO - Successfully uploaded 'test_scheduling.csv' to S3\n"
     ]
    }
   ],
   "source": [
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = DataFrame(data=d)\n",
    "\n",
    "s3 = S3(s3_key=\"grizly/\", file_name=\"test_scheduling.csv\").from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:23:49,326 - grizly.scheduling.registry - INFO - Submitting job s3_grizly_test_scheduling_listener...\n",
      "2020-12-10 17:23:54,687 - grizly.scheduling.registry - INFO - Job s3_grizly_test_scheduling_listener finished with status success\n",
      "2020-12-10 17:24:00,563 - grizly.scheduling.registry - INFO - Job email_upstream_success has been enqueued\n",
      "2020-12-10 17:24:03,567 - grizly.scheduling.registry - INFO - Job email_upstream_result_change has been enqueued\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2020-12-10 17:23:47+00:00'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.submit(scheduler_address=\"10.125.68.177:8999\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failing job's traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your job failed you can easily check the details of the last job run using `Job.last_run` and checking `traceback` property. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:24:04,819 - grizly.scheduling.registry - INFO - Job failing_job successfully registered\n",
      "2020-12-10 17:24:06,393 - grizly.scheduling.registry - INFO - Submitting job failing_job...\n",
      "2020-12-10 17:24:07,967 - grizly.failing_function - INFO - I'm adding 2 + 2...\n",
      "2020-12-10 17:24:11,542 - grizly.scheduling.registry - INFO - Job failing_job finished with status fail\n"
     ]
    }
   ],
   "source": [
    "def failing_func():\n",
    "    logger = logging.getLogger(\"grizly\").getChild(\"failing_function\")\n",
    "    a = 2\n",
    "    b = '2'\n",
    "    logger.info(f\"I'm adding {str(a)} + {str(b)}...\")\n",
    "    return a + b\n",
    "\n",
    "job = Job(\"failing_job\")\n",
    "\n",
    "job.register(func=failing_func,\n",
    "             if_exists=\"replace\"\n",
    "            )\n",
    "\n",
    "job.submit(scheduler_address=\"10.125.68.177:8999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/grizly-0.4.2rc0-py3.8.egg/grizly/scheduling/registry.py\", line 1155, in submit\n",
      "    result = self.func(*args, **kwargs)\n",
      "  File \"<ipython-input-19-41af6e778f93>\", line 6, in failing_func\n",
      "    return a + b\n",
      "TypeError: unsupported operand type(s) for +: 'int' and 'str'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(job.last_run.traceback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job's logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using grizly logger (as in the `failing_func` in the example above) you can read your job's logs using `Job.last_run.logs` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm adding 2 + 2...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(job.last_run.logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unregister jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 17:24:26,911 - grizly.scheduling.registry - INFO - Job s3_grizly_test_scheduling_listener successfully removed from registry\n",
      "2020-12-10 17:24:32,766 - grizly.scheduling.registry - INFO - Job email_upstream_success successfully removed from registry\n",
      "2020-12-10 17:24:37,189 - grizly.scheduling.registry - INFO - Job email_upstream_result_change successfully removed from registry\n",
      "2020-12-10 17:24:40,330 - grizly.scheduling.registry - INFO - Job failing_job successfully removed from registry\n"
     ]
    }
   ],
   "source": [
    "Job(\"s3_grizly_test_scheduling_listener\").unregister(remove_job_runs=True)\n",
    "Job(\"email_upstream_success\").unregister(remove_job_runs=True)\n",
    "Job(\"email_upstream_result_change\").unregister(remove_job_runs=True)\n",
    "Job(\"failing_job\").unregister(remove_job_runs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
