{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "from pandas import DataFrame\n",
    "from boto3 import resource\n",
    "\n",
    "from grizly.scheduling.registry import Job\n",
    "from grizly import Email, S3\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you register a job you have to define tasks that your job will run. Let's define a function that returns last modified date of a file in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def get_last_modified_date(s3_key, file_name):\n",
    "    date = S3(s3_key=s3_key, file_name=file_name).last_modified\n",
    "    return str(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = get_last_modified_date(s3_key=\"grizly/\", file_name=\"test_scheduling.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jobs that are listening for some changes are called **listener jobs**. A good practise is to start their name with `listener` prefix so that they are easy to list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = Job(\"listener_s3_grizly_test_scheduling\")\n",
    "\n",
    "job.register(tasks=[task], \n",
    "             if_exists=\"replace\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just registered a job called `listener_s3_grizly_test_scheduling`. The name of the job is unique and you can always check its details with `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = Job(\"listener_s3_grizly_test_scheduling\")\n",
    "job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this job is not scheduled yet - it's not a cron job and it doesn't have any upstream jobs and it doesn't have any triggers. You can pass these parameters during registration or overwrite them later using `crons`, `upstream` or `triggers` attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add cron string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add now a cron string to our job to run every one minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.crons = \"* * * * *\"\n",
    "\n",
    "job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register jobs with upstream job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now register two jobs with upstream job `listener_s3_grizly_test_scheduling`. One will send an email whenever upstream finished with status `success` and the other will send an email whenever the upstream changed his result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def send_email(subject, body, to):\n",
    "    logger = logging.getLogger(\"distributed.worker\").getChild(\"email\")\n",
    "    e = Email(subject=subject, body=body, logger=logger)\n",
    "    e.send(to=to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = send_email(subject=\"Job success\",\n",
    "                   body=\"Job `listener_s3_grizly_test_scheduling` finished with status success.\", \n",
    "                   to=\"katarzyna.malina@te.com\")\n",
    "\n",
    "job = Job(\"email_upstream_succcess\")\n",
    "\n",
    "job.register(tasks=[task], \n",
    "             if_exists=\"replace\",\n",
    "             upstream={\"listener_s3_grizly_test_scheduling\": \"success\"}\n",
    "             )\n",
    "\n",
    "job.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = send_email(subject=\"File changed\",\n",
    "                   body=\"Somebody changed 'grizly/test_scheduling.csv' file!\", \n",
    "                   to=\"katarzyna.malina@te.com\")\n",
    "\n",
    "job = Job(\"email_upstream_result_change\")\n",
    "\n",
    "job.register(tasks=[task], \n",
    "               if_exists=\"replace\",\n",
    "               upstream={\"listener_s3_grizly_test_scheduling\": \"result_change\"}\n",
    "              )\n",
    "\n",
    "job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see now that `listener_s3_grizly_test_scheduling` has two downstream jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = Job(\"listener_s3_grizly_test_scheduling\")\n",
    "job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first run (in this case after one minute) you will be able to access `last_run` property with information about the last run of your job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unregister jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job(\"listener_s3_grizly_test_scheduling\").unregister(remove_job_runs=True)\n",
    "Job(\"email_upstream_succcess\").unregister(remove_job_runs=True)\n",
    "Job(\"email_upstream_result_change\").unregister(remove_job_runs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job(\"listener_s3_grizly_test_scheduling\").downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
